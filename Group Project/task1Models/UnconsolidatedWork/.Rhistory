m = matrix(0, length(gammasInd), 4)
for(i in 1:length(gammasInd))
{
m[i,newsIndRe[i]] = 1
}
brier <- m - gammas
brier <- brier^2
brier <- rowSums(brier)
brierTot <- sum(brier)
brierAvg <- brierTot/length(brier)
print("Brier score")
print(brierAvg)
eDecreasing<- function(n = 1000, eUpdater = function(i,C){return(min(1, C/i))}
)#Run at default 1000 times,
#eUpdater is the function that determines how eDecreases
{
armOneProb = 0.4
armTwoProb = 0.6
armOneReward = 0
armTwoReward = 0
armOneTimesRan = 0
armTwoTimesRan = 0
outcomeVector <- vector() #Average performance of the function
c = 4
e = 1
##Run both arms first,  to avoid divide by 0 error
armOneTimesRan = armOneTimesRan + 1
armOneReward = armOneReward + rbinom(1,size=1,prob=armOneProb)
outcomeVector[1]<- armOneReward
armTwoTimesRan = armTwoTimesRan + 1
armTwoReward = armTwoReward + rbinom(1,size=1,prob=armTwoProb)
outcomeVector[2] <- (armOneReward+armTwoReward)/2
##Run loop
for(i in 3:n)
{
##Decide on course of action (random or best)
if(as.logical(rbinom(1,size=1,prob=e)))
{
##Pick arm at random
if(as.logical(rbinom(1,size=1,prob=1/2)))
{
armOneTimesRan = armOneTimesRan + 1
armOneReward = armOneReward + rbinom(1,size=1,prob=armOneProb)
}
else
{
armTwoTimesRan = armTwoTimesRan + 1
armTwoReward = armTwoReward + rbinom(1,size=1,prob=armTwoProb)
}
}
else
{
##Pick best arm
if(armOneReward/armOneTimesRan > armTwoReward/armTwoTimesRan)
{
armOneTimesRan = armOneTimesRan + 1
armOneReward = armOneReward + rbinom(1,size=1,prob=armOneProb)
}
else
{
armTwoTimesRan = armTwoTimesRan + 1
armTwoReward = armTwoReward + rbinom(1,size=1,prob=armTwoProb)
}
}
##Decrease e
e <- eUpdater(i, c)
outcomeVector[i] <- (armOneReward+armTwoReward)/i
}
return(outcomeVector)# Returns a vector of the running average return,
#for future plotting
}
eDecreasing(1000)[1000]
Thompson<- function(n = 1000)#Run at default 100 times
{
alpha <- 1
beta <- 1
armOneProb = 0.4
armTwoProb = 0.6
armOneReward = 0
armTwoReward = 0
armOneTimesRan = 0
armTwoTimesRan = 0
outcomeVector <- vector()
##Run loop
for(i in 1:n)
{
M1 <- rbeta(1,alpha+(armOneReward),beta+(armOneTimesRan-armOneReward))
M2 <- rbeta(1,alpha+(armTwoReward),beta+(armTwoTimesRan-armTwoReward))
##Pick arm according to est probability
if(M1>M2)
{
armOneTimesRan = armOneTimesRan + 1
armOneReward = armOneReward + rbinom(1,size=1,prob=armOneProb)
}
else
{
armTwoTimesRan = armTwoTimesRan + 1
armTwoReward = armTwoReward + rbinom(1,size=1,prob=armTwoProb)
}
outcomeVector[i] <- (armOneReward+armTwoReward)/i
}
return(outcomeVector)
}
Thompson(1000)[1000]
eUpdater <- function(i,C){return(min(1, C/i))}
outcomes <- eDecreasing(200, eUpdater)
plot(x = 1:200, y = outcomes, ylim=c(0, 1),
xlab = "Times ran", ylab = "Average performance")
abline(h= 0.6)
eUpdater <- function(i,C){return(min(1, C/(i^2)))}
outcomes <- eDecreasing(200, eUpdater)
plot(x = 1:200, y = outcomes, ylim=c(0, 1),
xlab = "Times ran", ylab = "Average performance")
abline(h= 0.6)
n=500
eUpdater <- function(i,C){return(min(1, C/(i^2)))}
outcomesE <- eDecreasing(n, eUpdater)
outcomesT <- Thompson(n)
plot(1:n,outcomesE,type="l",col="red", ylim=c(0, 1),
xlab = "Times ran", ylab = "Average performance")
lines(1:n,outcomesT,col="green")
abline(h= 0.6)
knn.regression.test <- function(k,train.X,train.Y,test.X,test.Y,distances)
{
estimates <- vector()
dist <-  distances(train.X, test.X)
#Go through each data point to be tested
#and create a vector holding the responses of the k nearest neighbours
for(each in 1:dim(test.X)[1])
{
adjacency <- data.frame(train.Y, dist[,each])
colnames(adjacency) <- c("Train", "Distances")
adjacency <- adjacency[order(adjacency$Distances),]
#Calculate distance weighted mean
dis <- 0
weightDis <- 0
for(i in 1:k)
{
dis <- dis + 1/adjacency$Distances[i]
weightDis <- weightDis + 1/(adjacency$Distances[i]) * adjacency$Train[i]
}
estimates[each] = weightDis/dis
}
print(sum((test.Y-estimates)^2))
}
distances.l1 <- function(x,y) {
apply(y,1,function(p) apply(x,1,function(q) sum(abs(p-q))))
}
n <- 100
train.X <- matrix(sort(rnorm(n)),n,1)
train.Y <- (train.X < -0.5) + train.X*(train.X>0)+rnorm(n,sd=0.03)
plot(train.X,train.Y)
test.X <- matrix(sort(rnorm(n)),n,1)
test.Y <- (test.X < -0.5) + test.X*(test.X>0)+rnorm(n,sd=0.03)
k <- 2
knn.regression.test(k,train.X,train.Y,test.X,test.Y,distances.l1)
train.X <- matrix(rnorm(200),100,2)
train.Y <- train.X[,1]
test.X <- matrix(rnorm(100),50,2)
test.Y <- test.X[,1]
k <- 3
knn.regression.test(k,train.X,train.Y,test.X,test.Y,distances.l1)
#install.packages("lasso2")
distances.l2 <- function(x,y)
{
apply(y,1,function(p) apply(x,1,function(q) sqrt(sum((p-q)^2))))
}
library("lasso2")
data(Iowa)
train.X=as.matrix(Iowa[seq(1,33,2),1:9])
train.Y=c(Iowa[seq(1,33,2),10])
test.X=as.matrix(Iowa[seq(2,32,2),1:9])
test.Y=c(Iowa[seq(2,32,2),10])
k <- 5
knn.regression.test(k,train.X,train.Y,test.X,test.Y,distances.l2)
library(glmnet)
print("KNN")
knn.regression.test(k,train.X,train.Y,test.X,test.Y,distances.l2)
lm1 <- lm(Yield~. ,data = Iowa[seq(1,33,2),1:10])
estimates <- predict(lm1, (Iowa[seq(2,32,2),1:9] ))
print("Ordinary least squares")
print(sum(((Iowa[seq(2,32,2),10])-estimates)^2))
lambdas <- 10^seq(2, -2, by = -.1)
ridge <- glmnet(y = train.Y, x = train.X, lambda = lambdas)
lambdaFind <- cv.glmnet(y = train.Y, x = train.X, alpha = 0, lambda = lambdas)
optimalLambda <- lambdaFind$lambda.min
estimates <- predict(ridge, s = optimalLambda, newx = test.X)
print("Ridge regression")
print(sum(((Iowa[seq(2,32,2),10])-estimates)^2))
knitr::opts_chunk$set(echo = TRUE)
setwd("~/GitHub/ST344/task1Models")
library(rio)
library(data.table)
library(ggplot2)
library(dplyr)
library(xlsx)
library(robustHD)
myData <- import("cleanedData.csv", setclass= "tibble")
myData <- {myData %>%
group_by(ArtistPopularity, ArtistNumFollowers,
AlbumBestChartPosition, AlbumWeeksOnChart, AlbumWeeksNumberOne,
AlbumPopularity, Release_year, Release_month, Season, isPop, isFolk,
isRock, isIndie, isTechno, isRap, isJazz, isMetal, isBlues, isPunk) %>%
summarize(AlbumLoudness = mean(TrackLoudness),
AlbumTempo = mean(TrackTempo),
AlbumAvgDuration = mean(TrackDuration),
AlbumDanceability = mean(TrackDanceability),
AlbumEnergy = mean(TrackEnergy),
AlbumKey = mean(TrackKey),
AlbumSpeechiness = mean(TrackSpeechiness),
AlbumAcousticness = mean(TrackAcousticness),
AlbumInstrumentalness = mean(TrackInstrumentalness),
AlbumLiveness = mean(TrackLiveness),
AlbumValence = mean(TrackValence),
AlbumTimeSignature = mean(TrackTimeSignature),
AlbumTempo = mean(TrackTempo)
)}
musicalData <- select(ungroup(myData), -ArtistNumFollowers, -ArtistPopularity, -Release_year, -Release_month, -Season, -isPop, -isRock, -isIndie, -isFolk, -isMetal, -isTechno, -isBlues, -isRap, -isPunk,-isJazz)
library(leaps)
musicalData1 <- select(ungroup(myData), -ArtistNumFollowers, -ArtistPopularity, -Release_year, -Release_month, -Season, -isPop, -isRock, -isIndie, -isFolk, -isMetal, -isTechno, -isBlues, -isRap, -isPunk,-isJazz, -AlbumBestChartPosition,  -AlbumWeeksOnChart, -AlbumWeeksNumberOne)
models<-regsubsets(AlbumPopularity~. ,musicalData, nvmax = 8 )
summary(models)
musicalData2 <- select(ungroup(myData), -ArtistNumFollowers, -ArtistPopularity, -AlbumBestChartPosition,  -AlbumWeeksOnChart, -AlbumWeeksNumberOne)
models<-regsubsets(AlbumPopularity~. ,musicalData2, nvmax = 8 )
summary(models)
library(rio)
library(data.table)
library(dplyr)
myData <- import("cleanedData.csv", setclass= "tibble")
TestAlbums <- c("Shirley Bassey", "In Dreams","Meddle","London Calling",
"It Takes A Nation Of Millions To Hold Us Back",
"Absolutely", "Blue Lines","Dig Your Own Hole", "Yoshimi Battles The Pink Robots",
"Original Pirate Material",
"Disc-Overy", "What Went Down")
#TestAlbums <- import("test_albums_6.txt")[2]
#TestAlbums <- apply(TestAlbums, 1, function(x) gsub(".*: ","",x))
myData <- {myData %>%
group_by(AlbumName, ArtistPopularity, ArtistNumFollowers,
AlbumBestChartPosition, AlbumWeeksOnChart, AlbumWeeksNumberOne,
AlbumPopularity, Release_year, Release_month, Season, isPop, isFolk,
isRock, isIndie, isTechno, isRap, isJazz, isMetal, isBlues, isPunk) %>%
summarize(AlbumLoudness = mean(TrackLoudness),
AlbumTempo = mean(TrackTempo),
AlbumAvgDuration = mean(TrackDuration),
AlbumDanceability = mean(TrackDanceability),
AlbumEnergy = mean(TrackEnergy),
AlbumKey = mean(TrackKey),
AlbumSpeechiness = mean(TrackSpeechiness),
AlbumAcousticness = mean(TrackAcousticness),
AlbumInstrumentalness = mean(TrackInstrumentalness),
AlbumLiveness = mean(TrackLiveness),
AlbumValence = mean(TrackValence),
AlbumTimeSignature = mean(TrackTimeSignature),
AlbumTempo = mean(TrackTempo)
)}
myData <- ungroup(myData)
#names <- myData$AlbumName
#myData <- standardize(select(myData, -AlbumName, ))
#myData$AlbumName <- names
TestData <- filter(myData, AlbumName %in% TestAlbums)
TestData <- select(TestData, -AlbumName)
TrainData <- filter(myData, !AlbumName %in% TestAlbums)
TrainData <- select(TrainData, -AlbumName)
train.X <- as.matrix(select(TrainData, -AlbumPopularity))
train.Y <- as.matrix(select(TrainData, AlbumPopularity))
test.X <- as.matrix(select(TestData, -AlbumPopularity))
test.Y <- select(TestData, AlbumPopularity)
popVect <- test.Y
#train.X <- standardize(train.X)
train.Y <- (train.Y)
#train.Y <- standardize(train.Y)
#test.X <- standardize(test.X)
test.Y <- (test.Y)
GoodModel  <-  lm((AlbumPopularity) ~ AlbumAcousticness +AlbumValence + AlbumDanceability + isPunk +isBlues + isJazz+ isRock + isPop,data = TrainData)
print(sum((predict(GoodModel, TestData) - popVect)^2))
data.frame(popVect, predict(GoodModel, TestData), (predict(GoodModel, TestData) - popVect))
setwd("~/GitHub/ST344/task1Models")
library(rio)
library(data.table)
library(dplyr)
myData <- import("cleanedData.csv", setclass= "tibble")
TestAlbums <- c("Shirley Bassey", "In Dreams","Meddle","London Calling",
"It Takes A Nation Of Millions To Hold Us Back",
"Absolutely", "Blue Lines","Dig Your Own Hole", "Yoshimi Battles The Pink Robots",
"Original Pirate Material",
"Disc-Overy", "What Went Down")
#TestAlbums <- import("test_albums_6.txt")[2]
#TestAlbums <- apply(TestAlbums, 1, function(x) gsub(".*: ","",x))
myData <- {myData %>%
group_by(AlbumName, ArtistPopularity, ArtistNumFollowers,
AlbumBestChartPosition, AlbumWeeksOnChart, AlbumWeeksNumberOne,
AlbumPopularity, Release_year, Release_month, Season, isPop, isFolk,
isRock, isIndie, isTechno, isRap, isJazz, isMetal, isBlues, isPunk) %>%
summarize(AlbumLoudness = mean(TrackLoudness),
AlbumTempo = mean(TrackTempo),
AlbumAvgDuration = mean(TrackDuration),
AlbumDanceability = mean(TrackDanceability),
AlbumEnergy = mean(TrackEnergy),
AlbumKey = mean(TrackKey),
AlbumSpeechiness = mean(TrackSpeechiness),
AlbumAcousticness = mean(TrackAcousticness),
AlbumInstrumentalness = mean(TrackInstrumentalness),
AlbumLiveness = mean(TrackLiveness),
AlbumValence = mean(TrackValence),
AlbumTimeSignature = mean(TrackTimeSignature),
AlbumTempo = mean(TrackTempo)
)}
myData <- ungroup(myData)
#names <- myData$AlbumName
#myData <- standardize(select(myData, -AlbumName, ))
#myData$AlbumName <- names
TestData <- filter(myData, AlbumName %in% TestAlbums)
TestData <- select(TestData, -AlbumName)
TrainData <- filter(myData, !AlbumName %in% TestAlbums)
TrainData <- select(TrainData, -AlbumName)
train.X <- as.matrix(select(TrainData, -AlbumPopularity))
train.Y <- as.matrix(select(TrainData, AlbumPopularity))
test.X <- as.matrix(select(TestData, -AlbumPopularity))
test.Y <- select(TestData, AlbumPopularity)
popVect <- test.Y
#train.X <- standardize(train.X)
train.Y <- (train.Y)
#train.Y <- standardize(train.Y)
#test.X <- standardize(test.X)
test.Y <- (test.Y)
GoodModel  <-  lm((AlbumPopularity) ~ AlbumAcousticness +AlbumValence + AlbumDanceability + isPunk +isBlues + isJazz+ isRock + isPop,data = TrainData)
print(sum((predict(GoodModel, TestData) - popVect)^2))
data.frame(popVect, predict(GoodModel, TestData), (predict(GoodModel, TestData) - popVect))
anova(GoodModel)
GoodModel  <-  lm((AlbumPopularity) ~ AlbumAcousticness +AlbumValence + AlbumDanceability + isPunk +isBlues + isJazz+ isRock + isPop,data = TrainData)
print(sum((predict(GoodModel, TestData) - popVect)))
data.frame(popVect, predict(GoodModel, TestData), (predict(GoodModel, TestData) - popVect))
GoodModel  <-  lm((AlbumPopularity) ~ AlbumAcousticness +AlbumValence + AlbumDanceability + isPunk +isBlues + isJazz+ isRock + isPop,data = TrainData)
print(sum(abs(predict(GoodModel, TestData) - popVect)))
data.frame(popVect, predict(GoodModel, TestData), (predict(GoodModel, TestData) - popVect))
View(TrainData)
View(TestData)
TestData <- filter(myData, AlbumName %in% TestAlbums)
View(TestData)
GoodModel  <-  lm((AlbumPopularity) ~ (AlbumAcousticness +AlbumValence + AlbumDanceability + isPunk +isBlues + isJazz+ isRock + isPop),data = TrainData)
print(sum(abs(predict(GoodModel, TestData) - popVect)))
data.frame(popVect, predict(GoodModel, TestData), (predict(GoodModel, TestData) - popVect))
anova(GoodModel)
GoodModel3  <-  lm((AlbumPopularity) ~ AlbumLoudness+
AlbumTempo +
AlbumAvgDuration +
AlbumDanceability+
AlbumEnergy +
#AlbumKey+
AlbumSpeechiness +
AlbumAcousticness +
AlbumInstrumentalness+
AlbumLiveness+
AlbumValence +
#AlbumTimeSignature,
AlbumTempo, data = TrainData)
print(sum((predict(GoodModel3, TestData) - popVect)^2))
data.frame(popVect, predict(GoodModel3, TestData), (predict(GoodModel3, TestData) - popVect))
knitr::opts_chunk$set(echo = TRUE)
library(rio)
library(data.table)
library(dplyr)
library(pracma)
library(glmnet)
library(splus2R)
distances.l2 <- function(x,y)
{
apply(y,1,function(p) apply(x,1,function(q) nthroot(sum((p-q)^2),2)))
}
distances.l1 <- function(x,y) {
apply(y,1,function(p) apply(x,1,function(q) sum(abs(p-q))))
}
knn.regression.test <- function(k,train.X,train.Y,test.X,test.Y,distances)
{
estimates <- vector()
dist <-  distances(train.X, test.X)
#Go through each data point to be tested
#and create a vector holding the responses of the k nearest neighbours
for(each in 1:dim(test.X)[1])
{
adjacency <- data.frame(train.Y, dist[,each])
colnames(adjacency) <- c("Train", "Distances")
adjacency <- adjacency[order(adjacency$Distances),]
#Calculate distance weighted mean
dis <- 0
weightDis <- 0
for(i in 1:k)
{
dis <- dis + 1/adjacency$Distances[i]
weightDis <- weightDis + 1/(adjacency$Distances[i]) * adjacency$Train[i]
}
estimates[each] = weightDis/dis
}
print(sum((test.Y-estimates)^2))
return(estimates)
}
SourceData <- import("cleanedData.csv", setclass= "tibble")
TestAlbums <- c("Shirley Bassey", "In Dreams","Meddle","London Calling",
"It Takes A Nation Of Millions To Hold Us Back",
"Absolutely", "Blue Lines","Dig Your Own Hole", "Yoshimi Battles The Pink Robots",
"Original Pirate Material",
"Disc-Overy", "What Went Down")
myData <- {SourceData %>%
group_by(AlbumName,AlbumPopularity ,
Release_year, Release_month, Season, isPop, isFolk,
isRock, isIndie, isTechno, isRap, isJazz, isMetal, isBlues, isPunk) %>%
summarize(AlbumLoudness = mean(TrackLoudness),
AlbumTempo = mean(TrackTempo),
AlbumAvgDuration = mean(TrackDuration),
AlbumDanceability = mean(TrackDanceability),
AlbumEnergy = mean(TrackEnergy),
AlbumKey = mean(TrackKey),
AlbumSpeechiness = mean(TrackSpeechiness),
AlbumAcousticness = mean(TrackAcousticness),
AlbumInstrumentalness = mean(TrackInstrumentalness),
AlbumLiveness = mean(TrackLiveness),
AlbumValence = mean(TrackValence),
AlbumTimeSignature = mean(TrackTimeSignature),
AlbumTempo = mean(TrackTempo)
)}
##Commented out code can run the other models.
myData <- ungroup(myData)
#Best Model
myData <- select(myData, -AlbumAvgDuration, -AlbumKey, -AlbumSpeechiness,-AlbumTimeSignature)
#test2 Model
#myData <- select(myData, -AlbumAvgDuration, -AlbumKey, -AlbumSpeechiness,-AlbumTimeSignature, -AlbumDanceability)
#test2 Model
#myData <- select(myData, -AlbumAvgDuration, -AlbumKey,-AlbumTimeSignature, -isPop, -isFolk,
#                -isRock, -isIndie, -isTechno, -isRap, -isJazz, -isMetal, -isBlues, -isPunk)
for (each in 3:dim(myData)[2])
{
if (!is.number(myData[1,each]))
{
myData[,each] <- as.numeric(as.factor(unlist(myData[,each])))
}
myData[,each] <- standardize(myData[,each])
}
TestData <- filter(myData, AlbumName %in% TestAlbums)
TestData <- select(TestData, -AlbumName)
TrainData <- filter(myData, !AlbumName %in% TestAlbums)
TrainData <- select(TrainData, -AlbumName)
train.X <- as.matrix(select(TrainData, -AlbumPopularity))
train.Y <- as.matrix(select(TrainData, AlbumPopularity))
test.X <- as.matrix(select(TestData, -AlbumPopularity))
test.Y <- select(TestData, AlbumPopularity)
goodness <- vector()
for(k in 1:20)
{
print(k)
goodness[k] <- knn.regression.test(k,train.X,train.Y,test.X,test.Y, distances.l2)
}
print(which.min(goodness))
est <- knn.regression.test(2,train.X,train.Y,test.X,test.Y, distances.l2)
data.frame(est, test.Y, test.Y - est)
lambdas <- 10^seq(2, -2, by = -.2)
ridge <- glmnet(y = train.Y, x = train.X, lambda = lambdas)
lambdaFind <- cv.glmnet(y = train.Y, x = train.X, alpha = 0, lambda = lambdas)
optimalLambda <- lambdaFind$lambda.min
estimates <- predict(ridge, s = optimalLambda, newx = test.X)
print("Ridge regression")
print(sum(((test.Y-estimates)^2)))
myData <- {SourceData %>%
group_by(AlbumName, ArtistPopularity, ArtistNumFollowers,
AlbumBestChartPosition, AlbumWeeksOnChart, AlbumWeeksNumberOne,
AlbumPopularity, Release_year, Release_month, Season, isPop, isFolk,
isRock, isIndie, isTechno, isRap, isJazz, isMetal, isBlues, isPunk) %>%
summarize(AlbumLoudness = mean(TrackLoudness),
AlbumTempo = mean(TrackTempo),
AlbumAvgDuration = mean(TrackDuration),
AlbumDanceability = mean(TrackDanceability),
AlbumEnergy = mean(TrackEnergy),
AlbumKey = mean(TrackKey),
AlbumSpeechiness = mean(TrackSpeechiness),
AlbumAcousticness = mean(TrackAcousticness),
AlbumInstrumentalness = mean(TrackInstrumentalness),
AlbumLiveness = mean(TrackLiveness),
AlbumValence = mean(TrackValence),
AlbumTimeSignature = mean(TrackTimeSignature),
AlbumTempo = mean(TrackTempo)
)}
myData <- ungroup(myData)
TestData <- filter(myData, AlbumName %in% TestAlbums)
TestData <- select(TestData, -AlbumName)
TrainData <- filter(myData, !AlbumName %in% TestAlbums)
TrainData <- select(TrainData, -AlbumName)
train.X <- as.matrix(select(TrainData, -AlbumPopularity))
train.Y <- as.matrix(select(TrainData, AlbumPopularity))
test.X <- as.matrix(select(TestData, -AlbumPopularity))
test.Y <- select(TestData, AlbumPopularity)
Model1  <-  lm((AlbumPopularity) ~ AlbumAcousticness +AlbumValence + AlbumDanceability + isPunk +isBlues + isJazz+ isRock + isPop,data = TrainData)
print(sum((predict(Model1, TestData) - test.Y)^2))
data.frame(test.Y, predict(Model1, TestData), (predict(Model1, TestData) - test.Y))
Model2  <-  lm((AlbumPopularity) ~ ArtistPopularity+AlbumAcousticness +AlbumValence + AlbumDanceability + isPunk +isBlues + isJazz+ isRock + isPop + isFolk +isRap,data = TrainData)
print(sum((predict(Model2, TestData) - test.Y)^2))
data.frame(test.Y, predict(Model2, TestData), (predict(Model2, TestData) - test.Y))
Model3  <-  lm((AlbumPopularity) ~ ArtistPopularity+ArtistNumFollowers,data = TrainData)
print(sum((predict(Model3, TestData) - test.Y)^2))
data.frame(test.Y, predict(Model3, TestData), (predict(Model3, TestData) - test.Y))
Model4  <-  lm((AlbumPopularity) ~ AlbumLoudness+	AlbumTempo + AlbumAvgDuration +
AlbumDanceability+ AlbumEnergy +AlbumSpeechiness +
AlbumAcousticness + AlbumInstrumentalness+	AlbumLiveness+
AlbumValence + AlbumTempo, data = TrainData)
print(sum((predict(Model4, TestData) - test.Y)^2))
data.frame(test.Y, predict(Model4, TestData), (predict(Model4, TestData) - test.Y))
Model5  <-  lm((AlbumPopularity) ~ AlbumAcousticness +AlbumValence + AlbumDanceability + Release_year+
AlbumTempo+AlbumLoudness+AlbumAvgDuration+AlbumLiveness+AlbumTimeSignature+
AlbumKey, data = TrainData)
print(sum((predict(Model5, TestData) - test.Y)^2))
data.frame(test.Y, predict(Model5, TestData), (predict(Model5, TestData) - test.Y))
AllModel <- lm(AlbumPopularity ~. ,data = TrainData)
print(sum((predict(AllModel, TestData) - test.Y)^2))
data.frame(test.Y, predict(AllModel, TestData), (predict(AllModel, TestData) - test.Y))
